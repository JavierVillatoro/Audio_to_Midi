https://github.com/JavierVillatoro/Audio_to_Midi

- Mirar concepto batch 
- Grafica de error (curva) y confusion matrix (falsos positivos etc) , entender el concepto bien
- Mirar concepto incertidumbre , como dar medida de incertidumbre sobre algo (con la varianza)
- ¿Como de confiable clasificador para cada clase?
- Calcular CDF / red neuronal bayesiana
- PROBAR LOS DOS , UNO DE DOS FASES OTRO DE UNA ( SILENCIO ,C4,D4,E4)

- Expande o reduce. Dependera de tu problema usar escala mel o no. Pensar si escala.

project/
│
├── data/
│     ├── voice_1.wav
│     ├── midi_1.mid
│     └── ...
│
├── scripts/
│     ├── extract_cqt.py
│     ├── midi_to_labels.py
│     ├── build_dataset.py
│     └── train_model.py   
│
├── utils/
│     ├── audio_utils.py
│     ├── midi_utils.py
│     └── dataset_utils.py
│
└── requirements.txt

audio.wav → extract_cqt.py
midi.mid  → midi_to_labels.py
X, Y → build_dataset.py
modelo.py → entrenar CRNN

Estrategias:
Procesar en ventanas
Divide el audio largo en ventanas de 4 segundos, las pasas por el modelo y luego concatenas los vectores de salida.
Es la más común y segura.

Cambiar a 1600 Hz y reducir hop
Quitar Padding , mi modelo tiene tamaño fijo.???? seguro?? 

Ver si puedo reducir bins en cqt.
Tengo que usar ventanas de mismo tamaño que el midi? 

Preguntas examen:
- Definir coeficientes cepstrales , escala mel. 
- Clasificador con knn.
- Modelo de prediccion lineal.


Comprobar que todos los midi son del mismo size (666)

Visualización de tus labels + CQT

Normalizar valores cqt. ----- PROBLEMA QUE VA DE UNO EN UNO , MEJOR GLOBAL PRIMERO.
optuna -- buscar funcion. 
scipy -- usar para confusion matrix 

LO QUE FALTA 
Buscar los mejores hiperparametros usando optuna_hiperperametros.py 
Entrenar el modelo con los parametros
Graficar epoch/error
Graficar confusion matrix 
Entender todo bien y hacer el modelo practico. 
Masking padding cuando se entrene para concatenar 4s 
Poner barra de tiempo para umap , muy lento n_l=5 min=0.01 // Va muy lento , solo para repre

Poder guardar el modelo o sus pesos antes de entrenarlo ----> best_crnn_model.pth

----OPTUNA HIPERPARAMETROS----
 Optimización Finalizada
---------------------------------------------------
Mejor Pérdida de Validación: 0.2006
Mejores Hiperparámetros:
  hidden_dim: 128
  lr: 0.0009341062209856291
  batch_size: 8

Proximo proyecto con dataset maestro , intentar hacer un modelo de transcripcion automatica

Probar otras optimizaciones (Adam...)
Probar con otros modelos

Prompt 
Eres un profesional con mas de 20 años de experiencia 
y vas a ayudarme a obtener los mejores modelos de redes neuronales posibles,
quiero probar con otros modelos , actualmente estoy usando crnn. 
Las entradas con cqts normalizados (300,666,252) y la salida midis en 
ventanas de 666 , cada una con 0 como silencio 1 como C3(oC4 en librosa) 2 E3(E4) 3 G3(G4).  
Asi que la entrada es entradas de audio de 4 segundos. 
Que otros modelos podrian funcionar bien para este tipo de problemas? probar algo novedoso. 
Te paso el codigo para ponerte en contexto:


El CRNN es el estándar de la industria desde hace años 
(paper de CQTNet o los trabajos de Google Magenta de ~2017).
(LSTM/GRU) tienen problemas de lentitud en entrenamiento y 
limitaciones para capturar dependencias globales muy complejas,
aunque las bidireccionales mitigan esto un poco.

La Red de Seguridad: Tu código ya tiene la lógica de if avg_val_loss < BEST_VAL_LOSS. Esto 
significa que no hay riesgo de degradar el modelo. Si pones 200 épocas y el modelo empieza a 
hacer overfitting en la época 60, tu archivo .pth guardado seguirá siendo el de la época 60. 
Lo único que pierdes es tiempo de cómputo.

He modificado el bucle de entrenamiento para incluir:

Aumento de épocas a 100.

ReduceLROnPlateau: Bajará el LR si no mejora en 5 épocas.

Early Stopping: 
Si no mejora en 15 épocas, corta el entrenamiento automáticamente (ahorra tiempo).


Lo he hecho con transformer teniendo peores resultados si ponia early stopping. 
Voy a alargarlo hasta 100 epochs por si aprende

Parece que va a haber overfitting
Transformer pilla mejor el G3 , curioso. 

Hacer que se vea el midi de prueba original en la misma forma que los otros.

OPTUNA PARA CADA Modelo

Este script usa pYIN, que es el estándar "matemático". 
Si en el futuro necesitas una precisión extrema para audios con mucho 
ruido de fondo o reverberación (donde pYIN falla), el estándar basado 
en Inteligencia Artificial es CREPE

mejorar graficas para comparar

hacer midi de prueba original , guardarlo en amarillo y azul

