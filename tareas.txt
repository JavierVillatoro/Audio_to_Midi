https://github.com/JavierVillatoro/Audio_to_Midi

- Mirar concepto batch 
- Grafica de error (curva) y confusion matrix (falsos positivos etc) , entender el concepto bien
- Mirar concepto incertidumbre , como dar medida de incertidumbre sobre algo (con la varianza)
- ¿Como de confiable clasificador para cada clase?
- Calcular CDF / red neuronal bayesiana
- PROBAR LOS DOS , UNO DE DOS FASES OTRO DE UNA ( SILENCIO ,C4,D4,E4)

- Expande o reduce. Dependera de tu problema usar escala mel o no. Pensar si escala.

project/
│
├── data/
│     ├── voice_1.wav
│     ├── midi_1.mid
│     └── ...
│
├── scripts/
│     ├── extract_cqt.py
│     ├── midi_to_labels.py
│     ├── build_dataset.py
│     └── train_model.py   
│
├── utils/
│     ├── audio_utils.py
│     ├── midi_utils.py
│     └── dataset_utils.py
│
└── requirements.txt

audio.wav → extract_cqt.py
midi.mid  → midi_to_labels.py
X, Y → build_dataset.py
modelo.py → entrenar CRNN

Estrategias:
Procesar en ventanas
Divide el audio largo en ventanas de 4 segundos, las pasas por el modelo y luego concatenas los vectores de salida.
Es la más común y segura.

Cambiar a 1600 Hz y reducir hop
Quitar Padding , mi modelo tiene tamaño fijo.???? seguro?? 

Ver si puedo reducir bins en cqt.
Tengo que usar ventanas de mismo tamaño que el midi? 

Preguntas examen:
- Definir coeficientes cepstrales , escala mel. 
- Clasificador con knn.
- Modelo de prediccion lineal.


Comprobar que todos los midi son del mismo size (666)

Visualización de tus labels + CQT

Normalizar valores cqt. ----- PROBLEMA QUE VA DE UNO EN UNO , MEJOR GLOBAL PRIMERO.
optuna -- buscar funcion. 
scipy -- usar para confusion matrix 

LO QUE FALTA 
Buscar los mejores hiperparametros usando optuna_hiperperametros.py 
Entrenar el modelo con los parametros
Graficar epoch/error
Graficar confusion matrix 
Entender todo bien y hacer el modelo practico. 
Masking padding cuando se entrene para concatenar 4s 
Poner barra de tiempo para umap , muy lento n_l=5 min=0.01 // Va muy lento , solo para repre

Poder guardar el modelo o sus pesos antes de entrenarlo ----> best_crnn_model.pth

----OPTUNA HIPERPARAMETROS----
 Optimización Finalizada
---------------------------------------------------
Mejor Pérdida de Validación: 0.2006
Mejores Hiperparámetros:
  hidden_dim: 128
  lr: 0.0009341062209856291
  batch_size: 8

Proximo proyecto con dataset maestro , intentar hacer un modelo de transcripcion automatica

Probar otras optimizaciones (Adam...)
Probar con otros modelos

El CRNN es el estándar de la industria desde hace años 
(paper de CQTNet o los trabajos de Google Magenta de ~2017).
(LSTM/GRU) tienen problemas de lentitud en entrenamiento y 
limitaciones para capturar dependencias globales muy complejas,
aunque las bidireccionales mitigan esto un poco.

La Red de Seguridad: Tu código ya tiene la lógica de if avg_val_loss < BEST_VAL_LOSS. Esto 
significa que no hay riesgo de degradar el modelo. Si pones 200 épocas y el modelo empieza a 
hacer overfitting en la época 60, tu archivo .pth guardado seguirá siendo el de la época 60. 
Lo único que pierdes es tiempo de cómputo.

He modificado el bucle de entrenamiento para incluir:

Aumento de épocas a 100.

ReduceLROnPlateau: Bajará el LR si no mejora en 5 épocas.

Early Stopping: 
Si no mejora en 15 épocas, corta el entrenamiento automáticamente (ahorra tiempo).


Lo he hecho con transformer teniendo peores resultados si ponia early stopping. 
Voy a alargarlo hasta 100 epochs por si aprende

Parece que va a haber overfitting
Transformer pilla mejor el G3 , curioso. 

Hacer que se vea el midi de prueba original en la misma forma que los otros.

OPTUNA PARA CADA Modelo

Este script usa pYIN, que es el estándar "matemático". 
Si en el futuro necesitas una precisión extrema para audios con mucho 
ruido de fondo o reverberación (donde pYIN falla), el estándar basado 
en Inteligencia Artificial es CREPE

mejorar graficas para comparar

hacer midi de prueba original , guardarlo en amarillo y azul

vi que tengo que mejorar onset y frames , en unet si se ve mejor

RECORTAR IMAGENES MIDI Y HACER UNA IMAGEN PARA COMPARACION DE DIFERENTES MODELOS EN PRUEBA

--- Resumen Final Guardado ---
Modelo: CRNN | Loss: 1.3861
   Params: {'lr': 3.436385776662958e-05, 'batch_size': 32, 'hidden_dim': 128}
Modelo: AudioTransNet | Loss: 1.3850
   Params: {'lr': 0.0009745792347836478, 'batch_size': 16, 'd_model': 128, 'nhead': 4, 'num_layers': 2, 'dropout': 0.35255154499851116}
Modelo: AudioUNet | Loss: 1.3856
   Params: {'lr': 6.095812482818733e-05, 'batch_size': 32}

HACER PRUEBA 2 MAS LARGA Y FUERA DE TAMAÑO PADDING

Escenario mas real , por eso creo Prueba_2 que dura un minuto.

Trato la voz como instrumento, cqt , necesidad de onset y frames tras ver resultados

Importancia en piano por ser percusivo